{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802c5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import os\n",
    "import DL_models.utils as du\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from time import time\n",
    "import copy\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a221dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_samples( df: pd.DataFrame, target_columns: list, columns_to_drop: list = [], device: str = 'cuda',\n",
    "                                 test_size: float = 0.2):\n",
    "            \n",
    "        y = df[target_columns].to_numpy()\n",
    "        X = df.drop(columns= columns_to_drop).to_numpy()\n",
    "        \n",
    "        X_train , X_test , y_train , y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        X_train_tensor = torch.from_numpy(X_train).type(torch.float).to(device)\n",
    "        X_test_tensor = torch.from_numpy(X_test).type(torch.float).to(device)\n",
    "        y_test_tensor = torch.from_numpy(y_test).type(torch.float).to(device).squeeze()\n",
    "        y_train_tensor = torch.from_numpy(y_train).type(torch.float).to(device).squeeze()\n",
    "        \n",
    "        return (X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87061142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_samples2( df: pd.DataFrame, target_columns: list, features_list: list, device: str = 'cuda',\n",
    "                                 test_size: float = 0.2):\n",
    "            \n",
    "        y = df[target_columns].to_numpy()\n",
    "        \n",
    "        X = df[features_list].to_numpy()\n",
    "        \n",
    "        X_train , X_test , y_train , y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        X_train_tensor = torch.from_numpy(X_train).type(torch.float).to(device)\n",
    "        X_test_tensor = torch.from_numpy(X_test).type(torch.float).to(device)\n",
    "        y_test_tensor = torch.from_numpy(y_test).type(torch.float).to(device).squeeze()\n",
    "        y_train_tensor = torch.from_numpy(y_train).type(torch.float).to(device).squeeze()\n",
    "        \n",
    "        return (X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5559a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinuxDatasetObject(Dataset):\n",
    "    def __init__(self, dataset, labels):\n",
    "        self.dataset = dataset\n",
    "        self.labels = labels\n",
    "\n",
    "    def NumberOfFeatures(self):\n",
    "        return self.dataset.shape[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95e1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dataloader(train_data: LinuxDatasetObject, batch_size: int, shuffle: bool = True):\n",
    "    return DataLoader(train_data, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "def test_dataloader(test_data: LinuxDatasetObject, batch_size: int, shuffle: bool = False):\n",
    "    return DataLoader(test_data, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "def validation_dataloader(val_data: LinuxDatasetObject, batch_size: int, shuffle: bool = False):\n",
    "    return DataLoader(val_data, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70ea991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, pation: int = 15, min_delta: int = 0):\n",
    "        self.pation = pation\n",
    "        self.min_delta = min_delta\n",
    "        self.best_model = None\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, model: nn.Module, val_loss: float, name_of_the_model_save: str = \"result\"):\n",
    "        if self.best_loss == None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        elif val_loss <= self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.pation:\n",
    "                #model.load_state_dict(self.best_model)\n",
    "                #torch.save(self.best_model, f=name_of_the_model_save)\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37992644",
   "metadata": {},
   "outputs": [],
   "source": [
    "device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f383a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,features, classes, activationLayer):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.activationLayer = activationLayer\n",
    "        self.inputLayer = nn.Linear(features, features)\n",
    "        self.hiddenLayer1 = nn.Linear(features,features)\n",
    "        self.hiddenLayer2 = nn.Linear(features,features)\n",
    "        self.outputLayer = nn.Linear(features, classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        z = self.inputLayer(x)\n",
    "        z = self.activationLayer(self.hiddenLayer1(z))\n",
    "        z = self.dropout(z)\n",
    "        z = self.activationLayer(self.hiddenLayer2(z))\n",
    "        z = self.dropout(z)\n",
    "        z = self.outputLayer(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcdd10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#es = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c79ef90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6283bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_hdf(\"DL_models/data/dados.h5\")\n",
    "\n",
    "\n",
    "#features_pca = len(df_pca.axes[1])\n",
    "#features_selctk = len(df_selectk.axes[1]) - 1\n",
    "#features_variance = len(df_variance.axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd140d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = generate_train_test_samples(df_pca,[\"perf\"],[\"perf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99f09f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = LinuxDatasetObject(data[0],data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7322d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 = Model(features_pca -1 ,1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9066e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.AdamW(params=model1.parameters(), lr=0.001, fused=True)\n",
    "#loss_fn = nn.SmoothL1Loss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52bb6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader = train_dataloader(train, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e7e4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cofg_for_model(version: int, model):\n",
    "    if version == 1:\n",
    "        activation = nn.PReLU()\n",
    "        loss_fn = torchmetrics.MeanAbsolutePercentageError().to(device)\n",
    "    elif version == 2:\n",
    "        activation = nn.PReLU()\n",
    "        loss_fn = torchmetrics.MeanSquaredError().to(device).to(device)\n",
    "    elif version == 3:\n",
    "        activation = nn.ELU()\n",
    "        loss_fn = nn.SmoothL1Loss().to(device)\n",
    "    \n",
    "    #retorna loss activation e optimizer nessa ordem\n",
    "    return(loss_fn, activation, torch.optim.AdamW(model.parameters(), lr=0.001, fused=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a4cecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model1, loss_fn, optimizer, es, train_loader, data, feature,percentage):\n",
    "    epoch = 400\n",
    "    star_time = time()\n",
    "    for i in range(epoch):\n",
    "        for batch_data, batch_labels in train_loader:\n",
    "            model1.train()\n",
    "            y_pred = model1(batch_data).squeeze()\n",
    "\n",
    "            loss = loss_fn(y_pred, batch_labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                test_pred = model1(data[2]).squeeze()\n",
    "                loss_test = loss_fn(test_pred, data[3])\n",
    "            \n",
    "                loss_test = torch.Tensor.cpu(loss_test).detach().numpy()\n",
    "            \n",
    "            if es(model1, loss_test, f\"{feature}_{percentage}\"):\n",
    "                model1.to('cpu')\n",
    "                loss_fn.to('cpu')\n",
    "                del loss_fn\n",
    "                del optimizer\n",
    "                del model1\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                return  (es.best_loss, time() - star_time, i)\n",
    "    model1.to('cpu')\n",
    "    loss_fn.to('cpu')\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del model1\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return  (es.best_loss, time() - star_time, i)     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcb807bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_for_all_features(files: list[str], percentages: list[int]):\n",
    "    with open(\"feature_selection_experimente.csv\", \"w\") as f: \n",
    "        df = pd.read_hdf(\"DL_models/data/dados.h5\")\n",
    "        for file in files:\n",
    "            name = file.split(\"_\")\n",
    "            rank = pd.read_csv(f\"results/{file}\")\n",
    "            for percentage in percentages:\n",
    "                #EarlyStopping\n",
    "                es = EarlyStopping()\n",
    "            \n",
    "                #select the data\n",
    "                cut = rank['importance'].quantile(percentage)\n",
    "                top_percent = rank[rank['importance'] >= cut][\"features\"]\n",
    "                number_of_features = len(top_percent)\n",
    "                data = generate_train_test_samples2(df,[\"perf\"],top_percent)\n",
    "                train = LinuxDatasetObject(data[0],data[1])\n",
    "                train_loader = train_dataloader(train, 4096)\n",
    "            \n",
    "                #get hyperparamiters\n",
    "                model1 = Model(number_of_features,1,nn.ELU())\n",
    "                model1.to(device)\n",
    "                loss_fn, activation, opt = get_cofg_for_model(1, model1)\n",
    "            \n",
    "                #train the model\n",
    "                best_loss, time, epoch = train_model(model1, loss_fn, opt, es, train_loader, data, name, percentage)\n",
    "            \n",
    "                #write the results\n",
    "                #output = pd.read_csv(\"~\")\n",
    "                nova_linha = {\"name\":name,\"percentage\":1-percentage,\"best_loss\":best_loss,\"time\":time,\"epoch\":epoch}\n",
    "                #df = df.append(nova_linha, ignore_index=True)\n",
    "                #df.to_csv(\"feature_selection_experimente.csv\")\n",
    "                print(nova_linha)\n",
    "                f.write(str(name)+\",\"+str(1-percentage)+\",\"+str(best_loss)+\",\"+str(time)+\",\"+str(epoch))\n",
    "                print(f\"{name}_{1-percentage} exectuded\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfe3f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages =[0.9,0.8,0.7,0.5,0.3,0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f432d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiels = os.listdir(\"results\")\n",
    "files = fiels[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b0df61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': ['feature', 'importance', 'GB.csv'], 'percentage': 0.09999999999999998, 'best_loss': array(0.16208723, dtype=float32), 'time': 534.7122533321381, 'epoch': 29}\n",
      "['feature', 'importance', 'GB.csv']_0.09999999999999998 exectuded\n",
      "{'name': ['feature', 'importance', 'GB.csv'], 'percentage': 0.19999999999999996, 'best_loss': array(0.16555892, dtype=float32), 'time': 511.45708179473877, 'epoch': 28}\n",
      "['feature', 'importance', 'GB.csv']_0.19999999999999996 exectuded\n",
      "{'name': ['feature', 'importance', 'GB.csv'], 'percentage': 0.30000000000000004, 'best_loss': array(0.16273493, dtype=float32), 'time': 522.2792568206787, 'epoch': 28}\n",
      "['feature', 'importance', 'GB.csv']_0.30000000000000004 exectuded\n",
      "{'name': ['feature', 'importance', 'GB.csv'], 'percentage': 0.5, 'best_loss': array(0.18378714, dtype=float32), 'time': 426.4525911808014, 'epoch': 23}\n",
      "['feature', 'importance', 'GB.csv']_0.5 exectuded\n",
      "{'name': ['feature', 'importance', 'GB.csv'], 'percentage': 0.7, 'best_loss': array(0.17915295, dtype=float32), 'time': 447.4760661125183, 'epoch': 24}\n",
      "['feature', 'importance', 'GB.csv']_0.7 exectuded\n",
      "{'name': ['feature', 'importance', 'GB.csv'], 'percentage': 0.9, 'best_loss': array(0.16413294, dtype=float32), 'time': 519.2986645698547, 'epoch': 28}\n",
      "['feature', 'importance', 'GB.csv']_0.9 exectuded\n",
      "{'name': ['feature', 'importance', 'DT.csv'], 'percentage': 0.09999999999999998, 'best_loss': array(0.25823745, dtype=float32), 'time': 22.720160961151123, 'epoch': 21}\n",
      "['feature', 'importance', 'DT.csv']_0.09999999999999998 exectuded\n",
      "{'name': ['feature', 'importance', 'DT.csv'], 'percentage': 0.19999999999999996, 'best_loss': array(0.13817044, dtype=float32), 'time': 132.71904587745667, 'epoch': 78}\n",
      "['feature', 'importance', 'DT.csv']_0.19999999999999996 exectuded\n",
      "{'name': ['feature', 'importance', 'DT.csv'], 'percentage': 0.30000000000000004, 'best_loss': array(0.13872202, dtype=float32), 'time': 166.66100525856018, 'epoch': 65}\n",
      "['feature', 'importance', 'DT.csv']_0.30000000000000004 exectuded\n",
      "{'name': ['feature', 'importance', 'DT.csv'], 'percentage': 0.5, 'best_loss': array(0.27148485, dtype=float32), 'time': 13.569069862365723, 'epoch': 2}\n",
      "['feature', 'importance', 'DT.csv']_0.5 exectuded\n",
      "{'name': ['feature', 'importance', 'DT.csv'], 'percentage': 0.7, 'best_loss': array(0.14272152, dtype=float32), 'time': 420.43328833580017, 'epoch': 43}\n",
      "['feature', 'importance', 'DT.csv']_0.7 exectuded\n",
      "{'name': ['feature', 'importance', 'DT.csv'], 'percentage': 0.9, 'best_loss': array(0.17667724, dtype=float32), 'time': 456.6608717441559, 'epoch': 24}\n",
      "['feature', 'importance', 'DT.csv']_0.9 exectuded\n",
      "{'name': ['feature', 'importance', 'RF.csv'], 'percentage': 0.09999999999999998, 'best_loss': array(0.15047516, dtype=float32), 'time': 128.508385181427, 'epoch': 103}\n",
      "['feature', 'importance', 'RF.csv']_0.09999999999999998 exectuded\n",
      "{'name': ['feature', 'importance', 'RF.csv'], 'percentage': 0.19999999999999996, 'best_loss': array(0.13636215, dtype=float32), 'time': 142.58717489242554, 'epoch': 90}\n",
      "['feature', 'importance', 'RF.csv']_0.19999999999999996 exectuded\n",
      "{'name': ['feature', 'importance', 'RF.csv'], 'percentage': 0.30000000000000004, 'best_loss': array(0.13519229, dtype=float32), 'time': 178.19370436668396, 'epoch': 69}\n",
      "['feature', 'importance', 'RF.csv']_0.30000000000000004 exectuded\n",
      "{'name': ['feature', 'importance', 'RF.csv'], 'percentage': 0.5, 'best_loss': array(0.16518535, dtype=float32), 'time': 214.23043847084045, 'epoch': 37}\n",
      "['feature', 'importance', 'RF.csv']_0.5 exectuded\n",
      "{'name': ['feature', 'importance', 'RF.csv'], 'percentage': 0.7, 'best_loss': array(0.15841568, dtype=float32), 'time': 337.99806690216064, 'epoch': 34}\n",
      "['feature', 'importance', 'RF.csv']_0.7 exectuded\n",
      "{'name': ['feature', 'importance', 'RF.csv'], 'percentage': 0.9, 'best_loss': array(0.17425852, dtype=float32), 'time': 404.7095251083374, 'epoch': 26}\n",
      "['feature', 'importance', 'RF.csv']_0.9 exectuded\n"
     ]
    }
   ],
   "source": [
    "train_model_for_all_features(files, percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3e6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45505816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(data[3].cpu().detach().numpy()[:100], color = 'b')\n",
    "#pred = model1(data[2]).squeeze()\n",
    "#plt.plot(pred.cpu().detach().numpy()[:100], color = 'r', linestyle = 'dashed')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2c829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
